\section{Future Work}
A few suggestions for future works, we suggest introducing a more sophisticated refactoring detection tool, we noticed that some commits that include several different refactorings on the same piece of code only got recognized as a single refactoring type, while several were involved. This could give further insights in the results we have found regarding RQ1.

Furthermore we suggest finding a more sophisticated method for asserting software maintainability, perhaps considering several granularity levels, from system to method level. We have seen that there is already several methods proposed, each having their own flaws, we think the CK metrics are a good starting point for the assessment with possibly including the Hallstead complexity measures \cite{halstead1977elements} since they both give insight on the size and complexity of a system or piece of code, which we consider key factors of maintainability.

A further consideration that might prove interesting is to look into the inverse correlation of that we have analysed in RQ2, i.e. is there a correlation between a significant maintainability improving production code refactor and a similar improvement in test code. By analysing this correlation developers might be pushed to keep their test code in as good shape as their production code. Since having higher quality test code has proven to give higher throughput and productivity \cite{athanasiou2011constructing}. 

At last we would recommend using more repositories to evaluate the refactors over the course of a project. During time constraints we were only able to take three repositories into consideration, however since the data has showed us that there is a inconsistency of refactors used over the three projects, we recommend using more repositories to evaluate in order to speculate whether the results are not biased on one specific project.